{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import scanpy as sc\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from anndata import AnnData\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import corescpy as cr\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 500\n",
    "sc.settings.set_figure_params(dpi=100, frameon=False, figsize=(20, 20))\n",
    "\n",
    "palette = \"tab20\"\n",
    "\n",
    "# Column Names (from Metadata & To Be Created)\n",
    "col_cell_type = \"Annotation\"  # for eventual cluster annotation column\n",
    "\n",
    "col_sample_id_o, col_sample_id, col_condition, col_subject,  = (\n",
    "    cr.tl.COL_SAMPLE_ID_O, cr.tl.COL_SAMPLE_ID,\n",
    "    cr.tl.COL_CONDITION, cr.tl.COL_SUBJECT)\n",
    "col_inflamed, col_stricture = (cr.tl.COL_INFLAMED, cr.tl.COL_STRICTURE)\n",
    "col_fff = cr.tl.COL_FFF  # column in which to store data file path\n",
    "col_tangram = cr.tl.COL_TANGRAM  # for future Tangram imputation\n",
    "col_segment = cr.tl.COL_SEGMENT\n",
    "key_uninfl, key_infl, key_stric = (\n",
    "    cr.tl.KEY_UNINFLAMED, cr.tl.KEY_INFLAMED,\n",
    "    cr.tl.KEY_STRICTURE)\n",
    "\n",
    "\n",
    "def construct_file(sample=None, run=\"CHO-001\", slide=None,\n",
    "                   date=None, timestamp=None,\n",
    "                   panel_id=\"TUQ97N\", prefix=\"output-XETG00189\",\n",
    "                   project_owner=\"EA\", directory=None):\n",
    "    \"\"\"Construct file path from information.\"\"\"\n",
    "    if \"outputs\" not in directory and os.path.exists(\n",
    "            os.path.join(directory, \"outputs\")):\n",
    "        directory = os.path.join(directory, \"outputs\")\n",
    "    if sample is None:\n",
    "        run = [run] if isinstance(run, str) else run\n",
    "        panel_id = [panel_id] * len(run) if isinstance(\n",
    "            panel_id, str) else panel_id\n",
    "        fff = []\n",
    "        for i, x in enumerate(run):\n",
    "            d_x = os.path.join(directory, panel_id[i], x)\n",
    "            fff += [os.path.join(d_x, y) for y in os.listdir(d_x)]\n",
    "        return fff\n",
    "    if isinstance(sample, str):\n",
    "        sample = [sample]\n",
    "    print(directory)\n",
    "    panel_id, prefix, project_owner, slide, date, timestamp = [\n",
    "        [x] * len(sample) if isinstance(x, str) else list(x) if x else x\n",
    "        for x in [panel_id, prefix, project_owner, slide, date, timestamp]]\n",
    "    run = [run] * len(sample) if isinstance(run, (str, int, float)) else run\n",
    "    block = [\"-\".join(i) for i in zip(sample, panel_id, project_owner)]\n",
    "    fff = [f\"{prefix[i]}__{slide[i]}__{block[i]}\" for i in range(len(sample))]\n",
    "    if date is None or timestamp is None:\n",
    "        for i, x in enumerate(fff):  # iterate current file stems\n",
    "            ddd = os.path.join(directory, panel_id[i], run[i])\n",
    "            print(ddd)\n",
    "            matches = sum([x in d for d in os.listdir(ddd)])\n",
    "            if  matches != 1:\n",
    "                raise ValueError(f\"{x} found in 0 or multiple file paths\",\n",
    "                                 f\"\\n\\n{os.listdir(ddd)}\")\n",
    "            fff[i] = os.path.join(ddd, np.array(os.listdir(ddd))[np.where([\n",
    "                x in d for d in os.listdir(ddd)])[0][0]])  # find match\n",
    "    else:\n",
    "        fff = [os.path.join(directory, panel_id[i], run[i],\n",
    "                            f\"{x}__{date[i]}__{timestamp[i]}\")\n",
    "               for i, x in enumerate(fff)]\n",
    "    return fff\n",
    "\n",
    "\n",
    "def perform_qc_concatenated(selves):\n",
    "    hue = selves[0]._columns[\"col_sample_id\"]\n",
    "    ids = [str(s.rna.obs[hue].iloc[0]) for s in selves]\n",
    "    patterns = [(\"MT-\", \"mt-\"), (\"RPS\", \"RPL\", \"rps\", \"rpl\"), (\n",
    "        \"^HB[^(P)]\", \"^hb[^(p)]\")]  # pattern matching for gene symbols\n",
    "    patterns = dict(zip([\"mt\", \"ribo\", \"hb\"], patterns))  # dictionary\n",
    "    names = dict(zip([\"mt\", \"ribo\", \"hb\"],\n",
    "                        [\"Mitochondrial\", \"Ribosomal\", \"Hemoglobin\"]))\n",
    "    p_names = [names[k] if k in names else k for k in patterns]  # \"pretty\"\n",
    "    patterns_names = dict(zip(patterns, p_names))  # map abbreviated to pretty\n",
    "    adata = AnnData.concatenate(\n",
    "        *[x.rna for x in selves], join=\"outer\", batch_key=hue,\n",
    "        batch_categories=ids, index_unique=None, uns_merge=\"unique\")\n",
    "    qc_vars = []  # to hold mt, rb, hb, etc. if present in data\n",
    "    for k in patterns:  # calculate MT, RB, HB counts\n",
    "        gvars = adata.var_names.str.startswith(patterns[k])\n",
    "        if any(gvars):\n",
    "            qc_vars += [k]\n",
    "        adata.var[k] = gvars\n",
    "    pct_n = [f\"pct_counts_{k}\" for k in qc_vars]  # \"% counts\" variables\n",
    "    cgs = selves[0]._columns[\"col_gene_symbols\"] if selves[\n",
    "        0].rna.var.index.values[0] not in selves[0].rna.var_names else None\n",
    "    adata.obs = adata.obs.astype({col_condition: \"category\"})\n",
    "    ggg = list(set(genes).intersection(adata.var_names))\n",
    "    ctm = list(set([\"n_genes_by_counts\", \"total_counts\", \"log1p_total_counts\",\n",
    "                    \"cell_area\", \"nucleus_area\"]\n",
    "                ).intersection(adata.obs.columns))\n",
    "    vam = pct_n + ctm + [hue]  # QC variable names\n",
    "    mets_df = adata.obs[vam].rename_axis(\"Metric\", axis=1).rename(\n",
    "        {\"total_counts\": \"Total Counts in Cell\", \"cell_area\": \"Cell Area\",\n",
    "        \"nucleus_area\": \"Nucleus Area\",\n",
    "        \"n_genes_by_counts\": \"Genes Detected in Cell\",\n",
    "        \"log1p_total_counts\": \"Log-Normalized Total Counts\",\n",
    "        **patterns_names}, axis=1)  # rename\n",
    "    fff = sb.pairplot(\n",
    "        mets_df, hue=hue, height=3, diag_kind=\"hist\",\n",
    "        plot_kws=dict(marker=\".\", linewidth=0.05))  # pair\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Directories\n",
    "# Replace manually or mirror my file/directory tree in your home (`ddu`)\n",
    "ddu = os.path.expanduser(\"~\")\n",
    "ddm = \"/mnt/cho_lab\" if os.path.exists(\"/mnt/cho_lab\") else \"/mnt\"  # Spark?\n",
    "ddl = f\"{ddm}/disk2/elizabeth/data/shared-xenium-library\" if (\n",
    "    \"cho\" in ddm) else os.path.join(ddu, shared-xenium-library)\n",
    "ddx = f\"{ddm}/bbdata0/xenium\"  # mounted drive Xenium folder\n",
    "out_dir = os.path.join(ddl, \"outputs\", \"TUQ97N\", \"nebraska\")  # None = no save\n",
    "d_path = \"/mnt/cho_lab/disk2/elizabeth/data\"  # for other data\n",
    "file_ann = os.path.join(ddu, \"corescpy/examples/annotation_guide.xlsx\")  # AG\n",
    "col_assignment = \"Bin\"  # which column from annotation file to use\n",
    "file_mdf = os.path.join(ddl, \"Xenium_Samples_03152024.xlsx\")  # metadata\n",
    "\n",
    "# Tangram\n",
    "col_tangram = \"tangram_prediction\"\n",
    "# col_cell_type_sc, file_sc = \"ClusterAnnotation\", str(\n",
    "#     f\"{d_path}/2023-05-12_CombinedCD-v2_ileal_new.h5ad\")\n",
    "col_cell_type_sc, file_sc = \"cell_type\", f\"{d_path}/elmentaite_ileal.h5ad\"\n",
    "\n",
    "# Directories & Metadata\n",
    "run = \"CHO-005\"\n",
    "samples = \"all\"\n",
    "# samples = [\"50452A\", \"50452B\", \"50452C\"]\n",
    "# samples = [\"50564A4\", \"50618B5\"]\n",
    "\n",
    "# Input/Output Options\n",
    "plot_all_qc = False\n",
    "reload = False\n",
    "\n",
    "# Computing Resources\n",
    "gpu = False\n",
    "sc.settings.n_jobs = 4\n",
    "sc.settings.max_memory = 150\n",
    "\n",
    "# Processing & Clustering Options\n",
    "resolution = 0.5\n",
    "resolution_sub = 0.5\n",
    "min_dist = 0.3\n",
    "n_comps = 50\n",
    "# custom_thresholds = {col_qscore: [, None]}\n",
    "genes_subset, use_highly_variable = True, False  # genes to use in clustering\n",
    "kws_pp = dict(cell_filter_pmt=None, cell_filter_ncounts=[50, None],\n",
    "              cell_filter_ngene=[30, None], gene_filter_ncell=[3, None],\n",
    "              gene_filter_ncounts=[3, None], custom_thresholds=None,\n",
    "              kws_scale=dict(max_value=10, zero_center=True))\n",
    "\n",
    "# After this point, no more options to specify\n",
    "# Just code to infer the data file path from your specifications\n",
    "# and construct argument dictionaries and manipulate metadata and such.\n",
    "\n",
    "# Read Metadata & Other Information\n",
    "annot_df = pd.read_excel(file_ann)\n",
    "metadata = pd.read_excel(file_mdf, dtype={\"Slide ID\": str})\n",
    "if samples not in [\"all\", None]:  # subset by sample ID?\n",
    "    metadata = metadata.set_index(col_sample_id_o).loc[samples].reset_index()\n",
    "\n",
    "# Construct Clustering Argument Keyword Dictionaries\n",
    "if genes_subset is True:\n",
    "    genes_subset = list(annot_df.iloc[:, 0])\n",
    "kws_umap = dict(min_dist=min_dist, method=\"rapids\" if gpu else \"umap\")\n",
    "kws_cluster = dict(use_gpu=gpu, kws_umap=kws_umap, kws_neighbors=None,\n",
    "                   use_highly_variable=use_highly_variable, n_comps=n_comps,\n",
    "                   genes_subset=genes_subset, resolution=resolution)\n",
    "kws_subcluster = dict(method_cluster=\"leiden\", resolution=resolution_sub)\n",
    "\n",
    "# Revise Metadata & Construct Variables from Options\n",
    "metadata.loc[:, col_stricture] = metadata[col_stricture].replace(\n",
    "    {\"yes\": \"Stricture\", \"no\": \"None\"})  # stricture column\n",
    "metadata.loc[:, col_condition] = metadata.apply(lambda x: \"Stricture\" if x[\n",
    "    col_stricture] == \"Stricture\" else x[col_inflamed].capitalize(), axis=1)\n",
    "metadata.loc[:, col_sample_id] = metadata[[col_condition, col_sample_id_o]\n",
    "                                          ].apply(\"-\".join, axis=1)\n",
    "metadata = metadata.set_index(col_sample_id)\n",
    "fff = np.array(construct_file(run=run, directory=ddx))\n",
    "samps = np.array([i.split(\"__\")[2].split(\"-\")[0] for i in fff])\n",
    "for x in metadata[col_sample_id_o]:\n",
    "    metadata.loc[metadata[col_sample_id_o] == x, col_fff] = fff[np.where(\n",
    "        samps == x)[0][0]] if len(np.where(samps == x)[0]) > 0 else np.nan\n",
    "metadata = metadata.dropna(subset=[col_fff])\n",
    "file_path_dict = dict(zip(metadata.index.values, metadata[\"file_path\"]))\n",
    "kws_init = dict(col_batch=col_batch, col_subject=col_subject,\n",
    "                col_sample_id=col_sample_id, col_cell_type=col_cell_type)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Annotation File\n",
    "assign = pd.read_excel(file_ann, index_col=0).dropna(\n",
    "    subset=col_assignment).rename_axis(\"Gene\")\n",
    "marker_genes_dict = dict(assign.reset_index().groupby(col_assignment).apply(\n",
    "    lambda x: list(pd.unique(x.Gene))))  # to marker dictionary\n",
    "\n",
    "# Print Metadata\n",
    "metadata\n",
    "\n",
    "# Genes\n",
    "# genes = [\"CDKN1A\", \"CDKN2A\", \"TP53\", \"PLAUR\", \"PTGER4\", \"FTL\", \"IL6ST\"]\n",
    "# cell_types = [\"ILC3\", \"LTi-like NCR+ ILC3\", \"LTi-like NCR- ILC3\",\n",
    "#               \"ILCP\", \"Macrophages\", \"Stem cells\"]\n",
    "# palette = [\"r\", \"tab:pink\", \"m\", \"b\", \"tab:brown\", \"cyan\"]\n",
    "# High in inf. vs. un\n",
    "# OSM\n",
    "# IL13\n",
    "# IL1B\n",
    "# IL6\n",
    "# TNF\n",
    "# S100A8\n",
    "# S100A9\n",
    "# ------------------------------\n",
    "# High in stricture vs inf/un\n",
    "# PDGFRA\n",
    "# IL6ST\n",
    "# PTPN1\n",
    "# IFNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load Spatial Data\n",
    "suff = str(f\"res{re.sub('[.]', 'pt', str(resolution))}_dist\"\n",
    "           f\"{re.sub('[.]', 'pt', str(min_dist))}_npc{n_comps}\")  # file end\n",
    "selves, paths_he, file_mks, out_files = [], [], [], []\n",
    "for x in metadata.index.values:\n",
    "    self = cr.Spatial(metadata.loc[x][col_fff], library_id=x, **kws_init)\n",
    "    for i in metadata:  # add metadata for subject\n",
    "        self.rna.obs.loc[:, i] = str(metadata.loc[x][i])  # add metadata\n",
    "    selves += [self]\n",
    "    paths_he += [os.path.join(metadata.loc[x][\n",
    "        col_fff], \"aux_outputs/image_he.ome.tif\")]  # H&E paths\n",
    "        # out_files += [os.path.join(out_dir, f\"{x}.zarr\")]\n",
    "    if out_dir is not None:\n",
    "        out_files += [os.path.join(out_dir, f\"{x}__{suff}\")]\n",
    "    file_mks += [os.path.join(out_dir, f\"{x}__{suff}_markers.csv\")]\n",
    "\n",
    "# Reload Processed & Clustered Data (Optionally)\n",
    "if reload is True:\n",
    "    for i, s in enumerate(selves):\n",
    "        mks = file_mks[i] if os.path.exists(file_mks[i]) else None\n",
    "        s.update_from_h5ad(file=out_files[i], file_path_markers=mks)\n",
    "        print(s.adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files = []\n",
    "for x in metadata.index.values:\n",
    "    if out_dir is not None:\n",
    "        out_files += [os.path.join(out_dir, f\"{x}__{suff}\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reload is True:\n",
    "    for i, s in enumerate(selves):\n",
    "        s.plot_spatial(color=\"leiden\")\n",
    "        # s.plot_spatial(color=col_cell_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation & Sub-Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    # _ = s.cluster(**kws_cluster)\n",
    "    _ = s.annotate_clusters(file_ann, col_cell_type=\"leiden\",\n",
    "                            col_annotation=col_cell_type,\n",
    "                            col_assignment=col_assignment)  # annotate & write\n",
    "    s.plot_spatial(color=col_cell_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_epi = [\"BEST2+ Goblet Cell\", \"BEST4+ Epithelial\", \"EC Cells (NPW+)\",\n",
    "#            \"EC Cells (TAC1+)\", \"Enterocyte\", \"Epithelial\", \"Goblet Cell\",\n",
    "#            \"I Cells (CCK+)\", \"Paneth\", \"D Cells (SST+)\",\n",
    "#            \"Stem Cells\", \"N Cells (NTS+)\", \"K Cells (GIP+)\",\n",
    "#            # \"Colonocyte\",\n",
    "#            \"L Cells (PYY+)\", \"Tuft\", \"Microfold Cell\"]\n",
    "# cat_epi = list(np.array()[np.where([\"epithelial\" in x.lower()\n",
    "#                                     for x in marker_genes_dict])[0]])\n",
    "# file_ann_epi = pd.concat([pd.Series(marker_genes_dict[x]) for x in cat_epi],\n",
    "#                          keys=cat_epi, names=[\"Type\"]).to_frame(\n",
    "#                              \"Gene\").reset_index(0).set_index(\"Gene\")\n",
    "file_ann_epi = file_ann\n",
    "# key_cell_type, col_ann = [\"7\"], \"Subclustering_Epi\"\n",
    "key_cell_type, col_ann = None, \"leiden_sub\"\n",
    "for s in selves:\n",
    "    ann = s.subcluster(restrict_to=(col_cell_type, key_cell_type), copy=False,\n",
    "                       key_added=\"leiden_sub\", **kws_subcluster)\n",
    "    s.annotate_clusters(kws_annotation={\"model\": file_ann_epi,\n",
    "                                        \"col_assignment\": \"Bin\"},\n",
    "                        col_annotation=[col_ann, col_cell_type])\n",
    "    s.write(out_files[i])  # write object\n",
    "    s.plot_spatial(color=col_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation\n",
    "\n",
    "I used the following code to make an ileal subset of the Elmentaite data & run the find markers command (so that we don't have to repeat that step every iteration).\n",
    "\n",
    "```\n",
    "adata_sc = sc.read(\"/mnt/cho_lab/disk2/elizabeth/data/elmentaite.h5ad\"\n",
    "                   col_gene_symbols=\"feature_name\")\n",
    "adata_sc.var = adata_sc.var.reset_index().set_index(\"feature_name\")\n",
    "adata_sc = adata_sc[adata_sc.obs.tissue == \"small intestine\"]\n",
    "adata_sc = adata_sc[adata_sc.obs.Age_group.isin(\n",
    "    [\"Adult\", \"Pediatric\", \"Pediatric_IBD\"])]\n",
    "adata_sc = adata_sc[adata_sc.obs[\"cell_type\"].isin(adata_sc.obs[\n",
    "    \"cell_type\"].value_counts().loc[lambda x: x >= 2].index)]  # >= 2 cells\n",
    "sc.tl.rank_genes_groups(adata_sc, groupby=\"cell_type\",  use_raw=False,\n",
    "                        key_added=\"rank_genes_groups_cell_type\")\n",
    "adata_sc.write(\"/mnt/cho_lab/disk2/elizabeth/data/elmentaite_ileal.h5ad\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read scRNA-seq Data\n",
    "adata_sc = sc.read(file_sc)\n",
    "\n",
    "# Impute GEX & Predict Labels from sc-RNA-seq Integration\n",
    "# for i, s in enumerate(selves):\n",
    "i, s = 0, selves[0]\n",
    "out = s.impute(\n",
    "    adata_sc.copy(), col_cell_type=col_cell_type_sc,\n",
    "    # mode=\"cells\",\n",
    "    mode=\"clusters\",\n",
    "    markers=None,  # use all overlap\n",
    "    # markers=200,\n",
    "    plot=False, plot_density=False, plot_genes=None,\n",
    "    col_annotation=col_tangram,\n",
    "    out_file=os.path.dirname(out_files[i]) if out_files else None)\n",
    "    # adata_sp_new, sdata, adata_sc_n, ad_map, df_compare, fig = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sp_new, adata_sp, adata_sc_n, ad_map, df_compare, fig = out\n",
    "cr.pl.plot_spatial(adata_sp_new, color=col_tangram)  # plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = cr.pl.plot_integration_spatial(\n",
    "    adata_sp, adata_sp_new=adata_sp_new, adata_sc=adata_sc,\n",
    "    col_cell_type=col_cell_type, ad_map=ad_map, cmap=\"magma\",\n",
    "    df_compare=df_compare, plot_genes=None, perc=0.01,\n",
    "    col_annotation=col_annotation)\n",
    "figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = [\"Enterocyte\", \"Tuft\", \"Goblet\", \"Paneth\", \"Stem\"]\n",
    "\n",
    "cr.pl.plot_gex(adata_sp_new, col_tangram, kind=[\"dot\", \"matrix\"],\n",
    "               marker_genes_dict=dict(zip(cts, [\n",
    "                   marker_genes_dict[x] for x in cts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"leiden\", col_cell_type, col_tangram]:\n",
    "    for i, s in enumerate(selves):\n",
    "        s.write_clusters(\n",
    "            out_dir, file_prefix=out_files[i] if c != col_tangram else None,\n",
    "            col_cell_type=c, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sc_cp = adata_sc.copy()\n",
    "adata_sp_cp = adata_sp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import tangram as tg\n",
    "    from corescpy.processing.spatial_pp import project_genes_m\n",
    "\n",
    "    kwargs = {}\n",
    "    adata_sc, adata_sp = adata_sc_cp, adata_sp_cp\n",
    "\n",
    "    col_cell_type = \"cell_type\"\n",
    "    col_annotation = \"tangram_prediction\"\n",
    "    mode = \"clusters\"\n",
    "    device = \"gpu\"\n",
    "    markers = 100\n",
    "    gene_to_lowercase = False\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.1\n",
    "    density_prior = None\n",
    "    perc = 0.01\n",
    "    seed = 0\n",
    "\n",
    "    key = f\"rank_genes_groups_{col_cell_type}\"\n",
    "\n",
    "    if device == \"gpu\":\n",
    "        device = \"cuda:0\"\n",
    "    kws = {\"suffix\": kwargs.pop(\"suffix\", None)\n",
    "           }  # to construct .obs; suffix, density columns for each cell type\n",
    "\n",
    "    if mode == \"clusters\":  # if mapping ~ clusters rather than cells...\n",
    "        kwargs[\"cluster_label\"] = col_cell_type  # ...must give label column\n",
    "\n",
    "\n",
    "    if isinstance(markers, (int, float)) or markers is None:\n",
    "        # if makers not a list of pre-specified genes\n",
    "        mks = set(np.unique(pd.DataFrame(adata_sc.uns[key][\"names\"]).melt(\n",
    "            ).value.values)).intersection(set(adata_sp.var_names))\n",
    "        if isinstance(markers, (int, float)):  # if markers = #...\n",
    "            markers = list(pd.Series(list(mks)).sample(\n",
    "                int(markers)))  # ...random subset of overlapping markers\n",
    "        else:  # if markers = None...\n",
    "            markers = list(mks)  # ...use all overlapping genes\n",
    "    tg.pp_adatas(adata_sc, adata_sp, genes=markers,\n",
    "                 gene_to_lowercase=gene_to_lowercase)  # preprocess\n",
    "    if \"uniform_density\" not in adata_sp.obs:  # issue with Tangram?\n",
    "        adata_sp.obs[\"uniform_density\"] = np.ones(adata_sp.X.shape[\n",
    "            0]) / adata_sp.X.shape[0]  # uniform density calculation -> .obs\n",
    "    if \"rna_count_based_density\" not in adata_sp.obs:  # issue with Tangram?\n",
    "        ct_spot = np.array(adata_sp.X.sum(axis=1)).squeeze()  # cts per spot\n",
    "        adata_sp.obs[\"rna_count_based_density\"] = ct_spot / np.sum(ct_spot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ad_map = tg.map_cells_to_space(\n",
    "        adata_sc, adata_sp, mode=mode, device=device, random_state=seed,\n",
    "        learning_rate=learning_rate, num_epochs=num_epochs,\n",
    "        density_prior=density_prior, **kwargs)  # map cells on spatial spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tg.project_cell_annotations(\n",
    "        ad_map, adata_sp, annotation=col_cell_type)  # clusters -> space\n",
    "    print(adata_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    c_l = col_cell_type if mode == \"clusters\" else None\n",
    "    adata_sp_new = project_genes_m(ad_map, adata_sc, cluster_label=c_l,\n",
    "                                   gene_to_lowercase=gene_to_lowercase)  # GEX\n",
    "    print(adata_sc)\n",
    "    print(adata_sp_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    adata_sp_new.obsm[\"tangram_ct_pred\"] = adata_sp.obsm[\n",
    "        \"tangram_ct_pred\"].loc[adata_sp_new.obs.index]\n",
    "    df_compare = tg.compare_spatial_geneexp(adata_sp_new, adata_sp, adata_sc)\n",
    "    tmp, dfp, preds = cr.pp.construct_obs_spatial_integration(\n",
    "        adata_sp_new.copy(), adata_sc.copy(), col_cell_type, perc=perc,\n",
    "        col_annotation=col_annotation, **kws)  # normalized densities; labels\n",
    "    adata_sp_new.obsm[\"tangram\"] = tmp.obs[dfp.columns]\n",
    "    adata_sp_new.obs = adata_sp_new.obs.join(preds)\n",
    "    print(adata_sc)\n",
    "    print(adata_sp_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = cr.pl.plot_integration_spatial(\n",
    "    adata_sp, adata_sp_new=adata_sp_new, adata_sc=adata_sc,\n",
    "    col_cell_type=col_cell_type, ad_map=ad_map, cmap=\"magma\",\n",
    "    df_compare=df_compare, plot_genes=None, perc=0.01,\n",
    "    col_annotation=col_annotation)\n",
    "figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.read_excel(file_ann)\n",
    "adf\n",
    "\n",
    "i = 0\n",
    "self = selves[i]\n",
    "self.add_image(paths_he[i], name=\"H_E\", file_align=paths_he_align[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
