{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import scipy\n",
    "import scanpy as sc\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import corescpy as cr\n",
    "\n",
    "# Computing Resources\n",
    "gpu = False\n",
    "sc.settings.n_jobs = 8\n",
    "sc.settings.max_memory = 150\n",
    "\n",
    "# Display\n",
    "pd.options.display.max_colwidth = 1000\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 500\n",
    "sc.settings.set_figure_params(dpi=100, frameon=False, figsize=(20, 20))\n",
    "\n",
    "# Panel & Column Names (from Metadata & To Be Created)\n",
    "panel = \"XR4UZH\"\n",
    "# panel = \"TUQ97N\"\n",
    "suffix = \"\"  # no file suffix for object h5ad file (main object)\n",
    "capitalize_sample = True if panel == \"TUQ97N\" else False\n",
    "# suffix = \"_new\"  # suffix for object h5ad file (to avoid overwrite)\n",
    "\n",
    "# Samples/Runs\n",
    "run = None  # just look for samples in all Xenium runs for the panel\n",
    "# run = \"CHO-001\"  # run all from this run; so don't have to specify samples\n",
    "samples = \"all\"\n",
    "\n",
    "# Main Directories\n",
    "# Replace manually or mirror my file/directory tree in your home (`ddu`)\n",
    "ddu = os.path.expanduser(\"~\")\n",
    "ddm = \"/mnt/cho_lab\" if os.path.exists(\"/mnt/cho_lab\") else \"/mnt\"  # Spark?\n",
    "ddl = f\"{ddm}/disk2/{os.getlogin()}/data/shared-xenium-library\" if (\n",
    "    \"cho\" in ddm) else os.path.join(ddu, \"shared-xenium-library\")\n",
    "ddx = f\"{ddm}/bbdata2\"  # mounted drive Xenium folder\n",
    "out_dir = os.path.join(ddl, \"outputs\", panel, \"nebraska\")  # to save objects\n",
    "out_dir_plot = os.path.join(out_dir, \"plots\")  # plot directory\n",
    "out_subdir_markers = \"find_markers\"  # sub-directory under out_dir for markers\n",
    "# out_dir = None  # don't save\n",
    "file_mdf = os.path.join(ddl, f\"samples_{panel}.csv\")  # metadata file path\n",
    "\n",
    "# Automated Annotation Options\n",
    "file_ann = None  # to skip marker-based annotation\n",
    "# file_ann = os.path.join(ddu, \"corescpy/examples/markers_lineages.csv\")\n",
    "col_assignment = None  # column in annotation file whose labels to use\n",
    "# col_assignment = \"Bin\"\n",
    "# col_assignment = [\"group\", \"Bin\", \"Bin\"]  # (order corresponds to res_list)\n",
    "\n",
    "# Preprocessing Options\n",
    "outlier_mads = {\"n_counts\": [1.25, None]}\n",
    "kws_pp = dict(cell_filter_ngene=[3, None], gene_filter_ncell=[3, None],\n",
    "              gene_filter_ncounts=[3, None], custom_thresholds=None,\n",
    "              kws_scale=dict(max_value=10, zero_center=True),\n",
    "              outlier_mads=outlier_mads, method_norm=\"log\")  # preprocessing\n",
    "# kws_pp = dict(cell_filter_pmt=None, cell_filter_ncounts=[15, None],\n",
    "#               cell_filter_ngene=[3, None], gene_filter_ncell=[3, None],\n",
    "#               gene_filter_ncounts=[3, None], custom_thresholds=None,\n",
    "#               kws_scale=dict(max_value=10, zero_center=True),\n",
    "#               method_norm=\"log\")  # preprocessing keyword arguments\n",
    "# kws_pp = None   # if loading object already preprocessed\n",
    "\n",
    "# Clustering Options\n",
    "genes_subset = None  # subset genes used in clustering?\n",
    "# genes_subset = list(pd.read_csv(file_ann).iloc[:, 0])  # only cell markers\n",
    "kws_cluster = dict(kws_umap=dict(method=\"rapids\" if gpu else \"umap\"),\n",
    "                   genes_subset=genes_subset,  # use only markers\n",
    "                   use_gpu=gpu, use_highly_variable=False)\n",
    "# res_list = [1.5, 0.75, 0.5]  # resolutions (iterate clustering runs)\n",
    "# min_dist_list = [0, 0.3, 0.5]  # distances (order corresponds to res_list)\n",
    "# n_comps_list = [30, 30, 30]  # PCA components (order same as res_list)\n",
    "res_list = [1.5, 0.5]  # resolutions (iterate different clustering runs)\n",
    "min_dist_list = [0, 0.5]  # distances (order corresponds to res_list)\n",
    "n_comps_list = [30, 30]  # PCA components (order corresponds to res_list)\n",
    "kws_clustering_spatial = None  # specify to perform spatial clustering\n",
    "suffix_clustering_spatial = None  # column key for spatial clustering results\n",
    "# ^ should parallel the parameters, like normal clustering does\n",
    "# e.g., res0pt75_dist0pt3_npc30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Get constants (e.g., column names in metadata), read metadata, create dictionary of clustering parameters (so can iterate across different clustering specifications to make multiple versions, e.g., at multiple resolutions) using `res_list`, `min_dist_list`, and `n_comps_list`, make any output directories (e.g., for processed objects, plots, find markers results, Xenium Explorer cluster files) if any don't exist yet, load data into objects, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Constants\n",
    "constants_dict = cr.get_panel_constants(panel)\n",
    "col_sample_id_o, col_sample_id, col_condition, col_inflamed, col_subject = [\n",
    "    constants_dict[x] if x in constants_dict else None for x in [\n",
    "        \"col_sample_id_o\", \"col_sample_id\", \"col_condition\",\n",
    "        \"col_inflamed\", \"col_subject\"]]\n",
    "col_stricture, key_stricture, col_f, col_tangram, col_segment, col_object = [\n",
    "    constants_dict[x] if (x in constants_dict) else None for x in [\n",
    "        \"col_stricture\", \"key_stricture\", \"col_data_dir\",\n",
    "        \"col_tangram\", \"col_segment\", \"col_object\"]]\n",
    "\n",
    "# Construct Clustering Keyword Dictionary\n",
    "kws_clustering = {}\n",
    "for i in zip(res_list, min_dist_list, n_comps_list):\n",
    "    kws = {**kws_cluster}\n",
    "    kws.update({\"resolution\": i[0], \"n_comps\": i[2],\n",
    "                \"kws_umap\": {**kws_cluster[\"kws_umap\"], \"min_dist\": i[1]}})\n",
    "    suff = str(f\"res{re.sub('[.]', 'pt', str(kws['resolution']))}_dist\"\n",
    "               f\"{re.sub('[.]', 'pt', str(kws['kws_umap']['min_dist']))}\"\n",
    "               f\"_npc{kws['n_comps']}\")  # file path suffix\n",
    "    kws_clustering.update({suff: kws})\n",
    "\n",
    "# Read Metadata\n",
    "metadata = cr.pp.get_metadata_cho(\n",
    "    ddx, file_mdf, panel_id=panel, samples=samples, run=run,\n",
    "    capitalize_sample=capitalize_sample)  # get metadata\n",
    "print(\"\\n\\n\", metadata[list(set([\n",
    "    col_sample_id_o, col_subject, col_condition, col_inflamed, col_stricture,\n",
    "    col_segment]).intersection(metadata))])\n",
    "\n",
    "# Annotation File\n",
    "assign = pd.read_csv(file_ann).dropna(subset=col_assignment).set_index(\n",
    "    \"gene\").rename_axis(\"Gene\") if file_ann is not None else None\n",
    "# assign = assign[~assign.Quality.isin([-1])]  # drop low-quality markers\n",
    "if col_assignment is not None and isinstance(col_assignment, str):\n",
    "    col_assignment = [col_assignment] * len(res_list)  # same for each version\n",
    "\n",
    "# Create Objects\n",
    "[os.makedirs(x, exist_ok=True) for x in [\n",
    "    out_dir, out_dir_plot, os.path.join(out_dir, out_subdir_markers)] if x\n",
    "]  # make out directories if they don't exist yet\n",
    "kws_init = dict(col_sample_id=col_sample_id, col_subject=col_subject,\n",
    "                col_cell_type=f\"leiden_{list(kws_clustering.keys())[0]}\")\n",
    "selves = [None] * metadata.shape[0]  # to hold different samples\n",
    "for i, x in enumerate(metadata.index.values):\n",
    "    out = os.path.join(out_dir, x + suffix)  # object output path\n",
    "\n",
    "    # Ensure No Overwrite of Prior Preprocessing or Skipping Preprocessing\n",
    "    # without Loading Prior Preprocessed Object\n",
    "    if os.path.exists(out + \".h5ad\"):  # if processed object file exists...\n",
    "        if kws_pp is not None:  # don't overwrite with new preprocessing\n",
    "            raise ValueError(f\"\\n\\nProcessed object already exists!\\n{out}.\\n\"\n",
    "                             \"specify different file suffix, or set `kws_pp` \"\n",
    "                             \"to None to reload processed object.\")\n",
    "    elif kws_pp is None:  # if doesn't exist but pp parameters specified...\n",
    "        raise ValueError(f\"\\n\\nProcessed object doesn't exist!\\n{out}.\\n\"\n",
    "                         \"Specify `kws_pp` to perform new proprocessing \"\n",
    "                         \"or ensure processed object paths are correct.\")\n",
    "\n",
    "    # Load Data into Object (Update with Prior Preprocessed Object if Exists)\n",
    "    selves[i] = cr.Spatial(metadata.loc[x][col_f], library_id=x, **kws_init)\n",
    "    if os.path.exists(out + \".h5ad\") and kws_pp is None:\n",
    "        selves[i].update_from_h5ad(out)  # update with prior preprocessing\n",
    "\n",
    "    # Add metadata to object\n",
    "    for j in metadata.dropna(how=\"all\", axis=1):  # add metadata to .obs\n",
    "        selves[i].rna.obs.loc[:, j] = str(metadata.loc[x][j])\n",
    "    selves[i].rna.obs.loc[:, col_object] = out  # path for processed object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing, Leiden, Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i, s in enumerate(selves):\n",
    "    f_o = None if out_dir is None else str(s.rna.obs[col_object].iloc[0])\n",
    "\n",
    "    # Preprocessing\n",
    "    if kws_pp is not None:\n",
    "        print(\"\\n\\n\", kws_pp, \"\\n\\n\")\n",
    "        _ = s.preprocess(**kws_pp, figsize=(15, 15))  # preprocess\n",
    "    else:\n",
    "        print(f\"\\n\\n***** Using Prior Preprocessing\\n\\n{s.rna.obs.iloc[[0]]}\")\n",
    "\n",
    "    # Clustering at Different Resolutions & Minimum Distances & # of PCs\n",
    "    for j, x in enumerate(kws_clustering):\n",
    "\n",
    "        # Variables & Output Files\n",
    "        print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\\n\\n\")\n",
    "        cct, cca = f\"leiden_{x}\", f\"label_{x}\"  # Leiden & annotation columns\n",
    "\n",
    "        # Clustering & Find Markers\n",
    "        _ = s.cluster(**kws_clustering[x], key_added=cct, out_file=f_o)\n",
    "        _ = s.find_markers(col_cell_type=cct, kws_plot=False)  # DEGs\n",
    "\n",
    "        # Annotation\n",
    "        if assign is not None:  # annotate by marker list\n",
    "            _ = s.annotate_clusters(assign[[col_assignment[j]]],\n",
    "                                    col_cell_type=cct, col_annotation=cca)\n",
    "\n",
    "        # Create Xenium Explorer Cluster Files\n",
    "        if out_dir is not None:\n",
    "            for c in [k for k in [cct, cca] if k in s.rna.obs]:  # Explorer\n",
    "                s.write_clusters(out_dir, col_cell_type=c, overwrite=True,\n",
    "                                file_prefix=f\"{s._library_id}__\",\n",
    "                                n_top=out_subdir_markers)\n",
    "\n",
    "        # Write Final Object\n",
    "        if out_dir is not None:\n",
    "            s.write(f_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Clusters Individually (Save in Same PDF if `out_dir` is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(selves):\n",
    "    for x in kws_clustering:\n",
    "        print(f\"\\n\\n{'=' * 80}\\n{x}\\n{'=' * 80}\\n\\n\")\n",
    "        cct, cca =   # Leiden & annotation columns\n",
    "        for c in [f\"leiden_{x}\", f\"label_{x}\", f\"manual_{x}\"]:\n",
    "            if c not in s.rna.obs:\n",
    "                print(f\"\\n\\n{c} not in {s.rna.obs.columns}.\\n\\n\")\n",
    "            if out_dir_plot is not None:\n",
    "                pfp = os.path.join(out_dir_plot, s._library_id, f\"{c}.pdf\")\n",
    "                s.plot_clusters(col_cell_type=c, out_dir=pfp, multi_pdf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Clusters (Overall; No Save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in selves:\n",
    "    for j, x in enumerate(kws_clustering):\n",
    "        _ = s.plot_spatial(color=list(set([\n",
    "            f\"leiden_{x}\", f\"label_{x}\"]).intersection(s.rna.obs.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatially-Informed Clustering (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kws_clustering_spatial is not None:\n",
    "    for s in selves:\n",
    "        f_o = None if out_dir is None else str(s.rna.obs[col_object].iloc[0])\n",
    "        cct = f\"leiden_spatial_{suffix_clustering_spatial}\"\n",
    "        _ = s.cluster_spatial(key_added=cct, **kws_clustering_spatial)\n",
    "        _ = s.find_markers(col_cell_type=cct, kws_plot=False)\n",
    "        _ = s.annotate_clusters(assign[[col_assignment[-1]]], col_cell_type=cct,\n",
    "                                col_annotation=f\"annotation_{cct}\")\n",
    "        for c in [cct, f\"annotation_{cct}\"]:\n",
    "            s.plot_spatial(c)\n",
    "            if out_dir is not None:\n",
    "                s.write_clusters(out_dir, col_cell_type=c, overwrite=True,\n",
    "                                file_prefix=f\"{s._library_id}__\",\n",
    "                                n_top=out_subdir_markers)\n",
    "        if out_dir is not None:\n",
    "            s.write(f_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze\n",
    "\n",
    "The first clustering version (first specified in `res_list`) is the cell type column used by default in downstream analyses (because it was specified in `kws_init[\"col_cell_type\"]` when creating the object and thus is stored in `self._columns[\"col_cell_type\"]`). Specify `col_cell_type` as an argument in the following functions to use a different column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    s.calculate_centrality(n_jobs=sc.settings.n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Enrichment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    _ = s.calculate_neighborhood(figsize=(60, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Type Co-Occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for s in selves:\n",
    "    _ = s.find_cooccurrence(figsize=(60, 20), kws_plot=dict(wspace=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatially-Variable Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kws = dict(kws_plot=dict(legend_fontsize=\"large\"), figsize=(15, 15))\n",
    "for s in selves:\n",
    "    _ = s.find_svgs(genes=15, method=\"moran\", n_perms=10, **kws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in selves:\n",
    "#     s.plot_spatial(color=[\"TNF\", \"IL23\", col_cell_type])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
